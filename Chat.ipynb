{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yrubq8Of0geJ"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgATfpv2-DDu"
   },
   "outputs": [],
   "source": [
    "def request_to_df(request_dict):\n",
    "    df.dropna(inplace = True)\n",
    "\n",
    "    # Dropping unused columns\n",
    "    df.drop(['invoice_no', 'customer_id'], axis = 1, inplace = True)\n",
    "\n",
    "    # Feature engineering\n",
    "    df['total_purchase'] = df['price'] * df['quantity']  # Target variable\n",
    "\n",
    "    # Dropping rows where 'total_purchase' exceeds 450\n",
    "    df = df[df['total_purchase'] <= 450]\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    # Duplicating the DataFrame 3 times\n",
    "    df= pd.concat([df] * 3, ignore_index = True)\n",
    "\n",
    "    # Convert invoice_date to datetime and extract useful features\n",
    "    df['invoice_date'] = pd.to_datetime(df['invoice_date'], errors = 'coerce')\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['gender', 'category', 'payment_method', 'shopping_mall']\n",
    "    for col in categorical_cols:\n",
    "        df[f\"{col}_code\"] = df[col].astype('category').cat.codes\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7iJBqpE2dLi"
   },
   "outputs": [],
   "source": [
    "OPEN_AI_API_KEY = \"\"\n",
    "\n",
    "\n",
    "def ask_chat_gpt(client, prompt):\n",
    "\n",
    "    prompt = f\"\"\"Here is user prompt related to shopping preferences of people:\n",
    "\n",
    "    {prompt}\n",
    "\n",
    "    Please, convert it to nomalized format, that can be used in automazied processing. Convert prompt to JSON that containt following fields:\n",
    "        - age:            integer\n",
    "        - gender:         string, can be only 'Male' or 'Female'\n",
    "        - category:       string, can be only 'Toys', 'Souvenir', 'Food & Beverage', 'Cosmetics' or 'Books'\n",
    "        - payment_method: string, can be only 'Credit Card', 'Debit Card' or 'Cash'\n",
    "\n",
    "    Try you best to fill all fields. If it is impossivle, use 'Unknown' as default value for string fields, and 30 - for age.\n",
    "\n",
    "    Return only JSON with normalized data in plain string format.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Ти - універсальний асистент, що добре розбирається в людях.\"},\n",
    "    ]\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model      = \"gpt-4o-mini\", # \"gpt-4-turbo\",\n",
    "        messages   = messages,\n",
    "        max_tokens = 1300\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message.content\n",
    "\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1846,
     "status": "ok",
     "timestamp": 1733140333341,
     "user": {
      "displayName": "КН-31мп Титарчук Владислав",
      "userId": "18068440991967517166"
     },
     "user_tz": -120
    },
    "id": "NG95_6eQ2l9f",
    "outputId": "b2017b30-42f4-40dd-cc86-67efde2ee5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "ai_client = OpenAI(api_key = OPEN_AI_API_KEY)\n",
    "\n",
    "while True:\n",
    "\n",
    "    prompt = input()\n",
    "    if prompt == \"-\":\n",
    "        break\n",
    "\n",
    "    responce = ask_chat_gpt(ai_client, prompt)\n",
    "\n",
    "    start_index = responce.find('{')\n",
    "    end_index   = responce.rfind('}')\n",
    "    json_text   = responce[start_index:end_index + 1]\n",
    "\n",
    "    request_dict = json.loads(json_text)\n",
    "    request_df   = request_to_df(request_dict)\n",
    "\n",
    "    print(json.loads(json_text))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
